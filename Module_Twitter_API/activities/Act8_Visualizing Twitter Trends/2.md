 <!--title={Reading in the .txt file }-->

<!--badges={Web Development:}-->

# Reading in the .txt file 

Now that our data is collected, we will now prepare the data.

1. Start by importing the libraries that are needed for the analysis and visualization:

```
#Import all the needed libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import json
import seaborn as sns
import re
import collections
from wordcloud import WordCloud
```

2. Then, we will read the data that we have collected and process it. Remember that the output of the Streaming API is a JSON object for each tweet, with many fields that can provide very useful information. In the following block of code, we read these tweets from the .txt file where they are stored:

```python
#Reading the raw data collected from the Twitter Streaming API using #Tweepy. 
tweets_data = []
tweets_data_path = 'Brexit_tweets_1.txt'
tweets_file = open(tweets_data_path, "r") ##change to filename
for line in tweets_file:
    try:
        tweet = json.loads(line)
        tweets_data.append(tweet)
    except:
        continue
```

In the piece of code, you will have to change the string ***tweets_data_path\*** to the name of the document where you have stored your data. 

3. While downloading the data, there might be connection issues or other errors. To fix this, go into the .txt file on where we have stored the tweets and delete the error codes. To get rid of them, run the following line of code after reading the .txt file.

```python
#Error codes from the Twitter API can be inside the .txt document, #take them off
tweets_data = [x for x in tweets_data if not isinstance(x, int)]
```

4. Now, you can see how many *tweets* we have collected by inserting this line of code into your main function:

```python
print("The total number of Tweets is:",len(tweets_data))
```